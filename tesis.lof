\babel@toc {spanish}{}\relax 
\contentsline {figure}{\numberline {1}{\ignorespaces Mecanismo de daño a la piel relacionado con contaminantes}}{4}{figure.caption.9}%
\contentsline {figure}{\numberline {2}{\ignorespaces Incidencia y mortalidad por No Melanoma en el mundo}}{5}{figure.caption.10}%
\contentsline {figure}{\numberline {3}{\ignorespaces Ingresos del mercado del cuidado de la piel en Estados Unidos de 2019 a 2030 (en millones de dólares estadounidenses)}}{6}{figure.caption.11}%
\contentsline {figure}{\numberline {4}{\ignorespaces Infografía de la Proyección del Mercado Cosmético e Higiene Personal en Perú}}{7}{figure.caption.12}%
\contentsline {figure}{\numberline {5}{\ignorespaces Mapas de textura para arrugas y poros}}{15}{figure.caption.13}%
\contentsline {figure}{\numberline {6}{\ignorespaces Metodología propuesta por el primer antecedente}}{16}{figure.caption.14}%
\contentsline {figure}{\numberline {7}{\ignorespaces Comparación de la segmentación de arrugas en (a) la frente y (b) la región de los ojos}}{18}{figure.caption.16}%
\contentsline {figure}{\numberline {8}{\ignorespaces Estructura de la máscara refinada R-CNN para objetos de tamaño pequeño}}{20}{figure.caption.17}%
\contentsline {figure}{\numberline {9}{\ignorespaces Generador en SR-GAN con capas de convolución de subpíxeles}}{20}{figure.caption.18}%
\contentsline {figure}{\numberline {10}{\ignorespaces Metodología propuesta por el segundo antecedente}}{23}{figure.caption.19}%
\contentsline {figure}{\numberline {11}{\ignorespaces Comparación del modelo propuesto con otros 6 modelos de redes neuronales}}{24}{figure.caption.20}%
\contentsline {figure}{\numberline {12}{\ignorespaces Estructura de red de DeepLabV3+}}{25}{figure.caption.21}%
\contentsline {figure}{\numberline {13}{\ignorespaces El proceso de convolución separable en profundidad}}{26}{figure.caption.22}%
\contentsline {figure}{\numberline {14}{\ignorespaces Metodología propuesta por el tercer antecedente}}{27}{figure.caption.23}%
\contentsline {figure}{\numberline {15}{\ignorespaces Red neuronal con abandono. (a) Una red tradicional con dos capas ocultas; (b) Una instancia de una red adelgazada. Se han eliminado los nodos cruzados}}{29}{figure.caption.25}%
\contentsline {figure}{\numberline {16}{\ignorespaces Diagrama de flujo del sistema propuesto}}{30}{figure.caption.26}%
\contentsline {figure}{\numberline {17}{\ignorespaces Modelo totalmente convolucional propuesto para la segmentación de lesiones cutáneas}}{31}{figure.caption.27}%
\contentsline {figure}{\numberline {18}{\ignorespaces Metodología propuesta}}{34}{figure.caption.29}%
\contentsline {figure}{\numberline {19}{\ignorespaces Detección de edad y género}}{36}{figure.caption.30}%
\contentsline {figure}{\numberline {20}{\ignorespaces Análisis del tono de piel}}{36}{figure.caption.31}%
\contentsline {figure}{\numberline {21}{\ignorespaces Análisis de arrugas}}{36}{figure.caption.32}%
\contentsline {figure}{\numberline {22}{\ignorespaces Mapa de textura enmascarado utilizado como una arruga débilmente etiquetada}}{38}{figure.caption.33}%
\contentsline {figure}{\numberline {23}{\ignorespaces Entrenamiento en dos etapas para la segmentación de arrugas faciales}}{40}{figure.caption.34}%
\contentsline {figure}{\numberline {24}{\ignorespaces Metodología propuesta por el sexto antecedente}}{41}{figure.caption.35}%
\contentsline {figure}{\numberline {25}{\ignorespaces Comparación cualitativa con el método de preentrenamiento de eliminación de ruido}}{42}{figure.caption.36}%
\contentsline {figure}{\numberline {26}{\ignorespaces El algoritmo de K medias}}{45}{figure.caption.37}%
\contentsline {figure}{\numberline {27}{\ignorespaces Relación entre IA, ML y DL}}{47}{figure.caption.38}%
\contentsline {figure}{\numberline {28}{\ignorespaces Modelo de aprendizaje profundo}}{48}{figure.caption.39}%
\contentsline {figure}{\numberline {29}{\ignorespaces Arquitectura de un modelo CNN}}{52}{figure.caption.40}%
\contentsline {figure}{\numberline {30}{\ignorespaces Diagrama de Q, K, V (queries, keys, values)}}{54}{figure.caption.41}%
\contentsline {figure}{\numberline {31}{\ignorespaces Arquitectura de Transformer}}{58}{figure.caption.43}%
\contentsline {figure}{\numberline {32}{\ignorespaces Arquitectura de SENet}}{60}{figure.caption.45}%
\contentsline {figure}{\numberline {33}{\ignorespaces Arquitectura U-Net}}{61}{figure.caption.46}%
\contentsline {figure}{\numberline {34}{\ignorespaces Arquitectura Attention U-Net}}{62}{figure.caption.47}%
\contentsline {figure}{\numberline {35}{\ignorespaces Arquitectura U-Net con codificador MiT-B0}}{63}{figure.caption.48}%
\contentsline {figure}{\numberline {36}{\ignorespaces Arquitectura Mask R-CNN}}{64}{figure.caption.49}%
\contentsline {figure}{\numberline {37}{\ignorespaces Arrugas dinámicas}}{66}{figure.caption.50}%
\contentsline {figure}{\numberline {38}{\ignorespaces Arrugas estáticas}}{66}{figure.caption.51}%
\contentsline {figure}{\numberline {39}{\ignorespaces Melasma}}{67}{figure.caption.52}%
\contentsline {figure}{\numberline {40}{\ignorespaces Manchas solares (lentigos solares)}}{68}{figure.caption.53}%
\contentsline {figure}{\numberline {41}{\ignorespaces Hiperpigmentación postinflamatoria}}{68}{figure.caption.54}%
\contentsline {figure}{\numberline {42}{\ignorespaces Base de datos pública Flickr-Faces-HQ Dataset (FFHQ)}}{75}{figure.caption.55}%
\contentsline {figure}{\numberline {43}{\ignorespaces Diagrama de Metodología de Investigación}}{76}{figure.caption.56}%
\contentsline {figure}{\numberline {44}{\ignorespaces Diagrama Esperado de Preprocesamiento de los Datos}}{81}{figure.caption.57}%
\contentsline {figure}{\numberline {45}{\ignorespaces Diagrama Esperado del Desarrollo de los Modelos de Segmentación}}{85}{figure.caption.58}%
\contentsline {figure}{\numberline {46}{\ignorespaces Proceso de operacion del prototipo del sistema}}{92}{figure.caption.59}%
\contentsline {figure}{\numberline {47}{\ignorespaces Matriz de Confusión}}{93}{figure.caption.60}%
\contentsline {figure}{\numberline {48}{\ignorespaces Cronograma de actividades}}{96}{figure.caption.62}%
\contentsline {figure}{\numberline {49}{\ignorespaces Dataset recolectado de repositorios}}{99}{figure.caption.64}%
\contentsline {figure}{\numberline {50}{\ignorespaces Máscaras binarias generadas}}{100}{figure.caption.65}%
\contentsline {figure}{\numberline {51}{\ignorespaces Diagrama de Preprocesamiento Utilizado}}{101}{figure.caption.66}%
\contentsline {figure}{\numberline {52}{\ignorespaces Desarrollo del Modelo U-Net}}{102}{figure.caption.67}%
\contentsline {figure}{\numberline {53}{\ignorespaces Desarrollo del Modelo U-Net Attention}}{104}{figure.caption.68}%
\contentsline {figure}{\numberline {54}{\ignorespaces Desarrollo del Modelo U-Net con codificador MiT-B0}}{107}{figure.caption.69}%
\contentsline {figure}{\numberline {55}{\ignorespaces Desarrollo del Modelo Mask R-CNN}}{110}{figure.caption.70}%
\contentsline {figure}{\numberline {56}{\ignorespaces Diagrama de Desarrollo Utilizado}}{113}{figure.caption.71}%
\contentsline {figure}{\numberline {57}{\ignorespaces Entrenamiento del Modelo U-Net}}{114}{figure.caption.72}%
\contentsline {figure}{\numberline {58}{\ignorespaces Entrenamiento del Modelo U-Net Attention}}{116}{figure.caption.73}%
\contentsline {figure}{\numberline {59}{\ignorespaces Entrenamiento del Modelo U-Net con codificador MiT-B0}}{118}{figure.caption.74}%
\contentsline {figure}{\numberline {60}{\ignorespaces Entrenamiento del Modelo Mask R-CNN}}{120}{figure.caption.75}%
\contentsline {figure}{\numberline {61}{\ignorespaces Evaluación del U-Net}}{122}{figure.caption.76}%
\contentsline {figure}{\numberline {62}{\ignorespaces Comparación visual: imagen original, máscara real multicategoría y predicción del modelo para un caso con predominio de arrugas.}}{124}{figure.caption.77}%
\contentsline {figure}{\numberline {63}{\ignorespaces Comparación visual: ejemplo donde se observa el desempeño del modelo en la detección de manchas, destacando regiones correctamente identificadas y algunas áreas faltantes.}}{124}{figure.caption.78}%
\contentsline {figure}{\numberline {64}{\ignorespaces Comparación visual: caso mixto donde se presentan simultáneamente arrugas y manchas, mostrando la capacidad del modelo para diferenciar ambas clases en un mismo rostro.}}{124}{figure.caption.79}%
\contentsline {figure}{\numberline {65}{\ignorespaces Evaluación del U-Net Attention}}{125}{figure.caption.80}%
\contentsline {figure}{\numberline {66}{\ignorespaces Comparación visual: imagen original, máscara real multicategoría y predicción del modelo para un caso con predominio de arrugas.}}{127}{figure.caption.81}%
\contentsline {figure}{\numberline {67}{\ignorespaces Comparación visual: ejemplo donde se observa el desempeño del modelo en la detección de manchas, destacando regiones correctamente identificadas y algunas áreas faltantes.}}{127}{figure.caption.82}%
\contentsline {figure}{\numberline {68}{\ignorespaces Comparación visual: caso mixto donde se presentan simultáneamente arrugas y manchas, mostrando la capacidad del modelo para diferenciar ambas clases en un mismo rostro.}}{127}{figure.caption.83}%
\contentsline {figure}{\numberline {69}{\ignorespaces Evaluación del U-Net con codificador MiT-B0}}{128}{figure.caption.84}%
\contentsline {figure}{\numberline {70}{\ignorespaces Comparación visual: imagen original, máscara real multicategoría y predicción del modelo para un caso con predominio de manchas.}}{130}{figure.caption.85}%
\contentsline {figure}{\numberline {71}{\ignorespaces Comparación visual: ejemplo donde se observa el desempeño del modelo en la detección de manchas, destacando pocas regiones correctamente identificadas y la mayoría de áreas faltantes.}}{130}{figure.caption.86}%
\contentsline {figure}{\numberline {72}{\ignorespaces Comparación visual: ejemplo donde se observa el desempeño del modelo en la detección de manchas, destacando casi ninguna de las regiones correctamente identificadas y muchas áreas faltantes.}}{131}{figure.caption.87}%
\contentsline {figure}{\numberline {73}{\ignorespaces Evaluación del Mask R-CNN}}{131}{figure.caption.88}%
\contentsline {figure}{\numberline {74}{\ignorespaces Comparación visual: imagen original, máscara real multicategoría y predicción del modelo 1.}}{133}{figure.caption.89}%
\contentsline {figure}{\numberline {75}{\ignorespaces Comparación visual: imagen original, máscara real multicategoría y predicción del modelo 2.}}{133}{figure.caption.90}%
