\babel@toc {spanish}{}\relax 
\contentsline {figure}{\numberline {1}{\ignorespaces Mecanismo de daño a la piel relacionado con contaminantes}}{5}{figure.caption.9}%
\contentsline {figure}{\numberline {2}{\ignorespaces Incidencia y mortalidad por No Melanoma en el mundo}}{6}{figure.caption.10}%
\contentsline {figure}{\numberline {3}{\ignorespaces Ingresos del mercado del cuidado de la piel en Estados Unidos de 2019 a 2030 (en millones de dólares estadounidenses)}}{7}{figure.caption.11}%
\contentsline {figure}{\numberline {4}{\ignorespaces Infografía de la Proyección del Mercado Cosmético e Higiene Personal en Perú}}{8}{figure.caption.12}%
\contentsline {figure}{\numberline {5}{\ignorespaces Mapas de textura para arrugas y poros}}{16}{figure.caption.13}%
\contentsline {figure}{\numberline {6}{\ignorespaces Metodología propuesta por el primer antecedente}}{17}{figure.caption.14}%
\contentsline {figure}{\numberline {7}{\ignorespaces Comparación de la segmentación de arrugas en (a) la frente y (b) la región de los ojos}}{19}{figure.caption.16}%
\contentsline {figure}{\numberline {8}{\ignorespaces Estructura de la máscara refinada R-CNN para objetos de tamaño pequeño}}{21}{figure.caption.17}%
\contentsline {figure}{\numberline {9}{\ignorespaces Generador en SR-GAN con capas de convolución de subpíxeles}}{21}{figure.caption.18}%
\contentsline {figure}{\numberline {10}{\ignorespaces Metodología propuesta por el segundo antecedente}}{24}{figure.caption.19}%
\contentsline {figure}{\numberline {11}{\ignorespaces Comparación del modelo propuesto con otros 6 modelos de redes neuronales}}{25}{figure.caption.20}%
\contentsline {figure}{\numberline {12}{\ignorespaces Estructura de red de DeepLabV3+}}{26}{figure.caption.21}%
\contentsline {figure}{\numberline {13}{\ignorespaces El proceso de convolución separable en profundidad}}{27}{figure.caption.22}%
\contentsline {figure}{\numberline {14}{\ignorespaces Metodología propuesta por el tercer antecedente}}{28}{figure.caption.23}%
\contentsline {figure}{\numberline {15}{\ignorespaces Red neuronal con abandono. (a) Una red tradicional con dos capas ocultas; (b) Una instancia de una red adelgazada. Se han eliminado los nodos cruzados}}{30}{figure.caption.25}%
\contentsline {figure}{\numberline {16}{\ignorespaces Diagrama de flujo del sistema propuesto}}{31}{figure.caption.26}%
\contentsline {figure}{\numberline {17}{\ignorespaces Modelo totalmente convolucional propuesto para la segmentación de lesiones cutáneas}}{32}{figure.caption.27}%
\contentsline {figure}{\numberline {18}{\ignorespaces Metodología propuesta}}{35}{figure.caption.29}%
\contentsline {figure}{\numberline {19}{\ignorespaces Detección de edad y género}}{37}{figure.caption.30}%
\contentsline {figure}{\numberline {20}{\ignorespaces Análisis del tono de piel}}{37}{figure.caption.31}%
\contentsline {figure}{\numberline {21}{\ignorespaces Análisis de arrugas}}{37}{figure.caption.32}%
\contentsline {figure}{\numberline {22}{\ignorespaces Mapa de textura enmascarado utilizado como una arruga débilmente etiquetada}}{39}{figure.caption.33}%
\contentsline {figure}{\numberline {23}{\ignorespaces Entrenamiento en dos etapas para la segmentación de arrugas faciales}}{41}{figure.caption.34}%
\contentsline {figure}{\numberline {24}{\ignorespaces Metodología propuesta por el sexto antecedente}}{42}{figure.caption.35}%
\contentsline {figure}{\numberline {25}{\ignorespaces Comparación cualitativa con el método de preentrenamiento de eliminación de ruido}}{43}{figure.caption.36}%
\contentsline {figure}{\numberline {26}{\ignorespaces El algoritmo de K medias}}{46}{figure.caption.37}%
\contentsline {figure}{\numberline {27}{\ignorespaces Relación entre IA, ML y DL}}{48}{figure.caption.38}%
\contentsline {figure}{\numberline {28}{\ignorespaces Modelo de aprendizaje profundo}}{49}{figure.caption.39}%
\contentsline {figure}{\numberline {29}{\ignorespaces Arquitectura de un modelo CNN}}{53}{figure.caption.40}%
\contentsline {figure}{\numberline {30}{\ignorespaces Diagrama de Q, K, V (queries, keys, values)}}{55}{figure.caption.41}%
\contentsline {figure}{\numberline {31}{\ignorespaces Arquitectura de Transformer}}{59}{figure.caption.43}%
\contentsline {figure}{\numberline {32}{\ignorespaces Arquitectura de SENet}}{61}{figure.caption.45}%
\contentsline {figure}{\numberline {33}{\ignorespaces Arquitectura U-Net}}{62}{figure.caption.46}%
\contentsline {figure}{\numberline {34}{\ignorespaces Arquitectura Attention U-Net}}{63}{figure.caption.47}%
\contentsline {figure}{\numberline {35}{\ignorespaces Arquitectura U-Net con codificador MiT-B0}}{64}{figure.caption.48}%
\contentsline {figure}{\numberline {36}{\ignorespaces Arquitectura Mask R-CNN}}{65}{figure.caption.49}%
\contentsline {figure}{\numberline {37}{\ignorespaces Arrugas dinámicas}}{67}{figure.caption.50}%
\contentsline {figure}{\numberline {38}{\ignorespaces Arrugas estáticas}}{67}{figure.caption.51}%
\contentsline {figure}{\numberline {39}{\ignorespaces Melasma}}{68}{figure.caption.52}%
\contentsline {figure}{\numberline {40}{\ignorespaces Manchas solares (lentigos solares)}}{69}{figure.caption.53}%
\contentsline {figure}{\numberline {41}{\ignorespaces Hiperpigmentación postinflamatoria}}{69}{figure.caption.54}%
\contentsline {figure}{\numberline {42}{\ignorespaces Base de datos pública Flickr-Faces-HQ Dataset (FFHQ)}}{76}{figure.caption.55}%
\contentsline {figure}{\numberline {43}{\ignorespaces Diagrama de Metodología de Investigación}}{77}{figure.caption.56}%
\contentsline {figure}{\numberline {44}{\ignorespaces Diagrama Esperado de Preprocesamiento de los Datos}}{82}{figure.caption.57}%
\contentsline {figure}{\numberline {45}{\ignorespaces Diagrama Esperado del Desarrollo de los Modelos de Segmentación}}{86}{figure.caption.58}%
\contentsline {figure}{\numberline {46}{\ignorespaces Proceso de operacion del prototipo del sistema}}{93}{figure.caption.59}%
\contentsline {figure}{\numberline {47}{\ignorespaces Matriz de Confusión}}{94}{figure.caption.60}%
\contentsline {figure}{\numberline {48}{\ignorespaces Cronograma de actividades}}{97}{figure.caption.62}%
\contentsline {figure}{\numberline {49}{\ignorespaces Dataset recolectado de repositorios}}{100}{figure.caption.64}%
\contentsline {figure}{\numberline {50}{\ignorespaces Máscaras binarias generadas}}{101}{figure.caption.65}%
\contentsline {figure}{\numberline {51}{\ignorespaces Diagrama de Preprocesamiento Utilizado}}{102}{figure.caption.66}%
\contentsline {figure}{\numberline {52}{\ignorespaces Desarrollo del Modelo U-Net}}{103}{figure.caption.67}%
\contentsline {figure}{\numberline {53}{\ignorespaces Desarrollo del Modelo U-Net Attention}}{105}{figure.caption.68}%
\contentsline {figure}{\numberline {54}{\ignorespaces Desarrollo del Modelo U-Net con codificador MiT-B0}}{108}{figure.caption.69}%
\contentsline {figure}{\numberline {55}{\ignorespaces Desarrollo del Modelo Mask R-CNN}}{111}{figure.caption.70}%
\contentsline {figure}{\numberline {56}{\ignorespaces Diagrama de Desarrollo Utilizado}}{114}{figure.caption.71}%
\contentsline {figure}{\numberline {57}{\ignorespaces Entrenamiento del Modelo U-Net}}{115}{figure.caption.72}%
\contentsline {figure}{\numberline {58}{\ignorespaces Entrenamiento del Modelo U-Net Attention}}{117}{figure.caption.73}%
\contentsline {figure}{\numberline {59}{\ignorespaces Entrenamiento del Modelo U-Net con codificador MiT-B0}}{119}{figure.caption.74}%
\contentsline {figure}{\numberline {60}{\ignorespaces Entrenamiento del Modelo Mask R-CNN}}{121}{figure.caption.75}%
\contentsline {figure}{\numberline {61}{\ignorespaces Evaluación del U-Net}}{123}{figure.caption.76}%
\contentsline {figure}{\numberline {62}{\ignorespaces Comparación visual: imagen original, máscara real multicategoría y predicción del modelo para un caso con predominio de arrugas.}}{125}{figure.caption.77}%
\contentsline {figure}{\numberline {63}{\ignorespaces Comparación visual: ejemplo donde se observa el desempeño del modelo en la detección de manchas, destacando regiones correctamente identificadas y algunas áreas faltantes.}}{125}{figure.caption.78}%
\contentsline {figure}{\numberline {64}{\ignorespaces Comparación visual: caso mixto donde se presentan simultáneamente arrugas y manchas, mostrando la capacidad del modelo para diferenciar ambas clases en un mismo rostro.}}{125}{figure.caption.79}%
\contentsline {figure}{\numberline {65}{\ignorespaces Evaluación del U-Net Attention}}{126}{figure.caption.80}%
\contentsline {figure}{\numberline {66}{\ignorespaces Comparación visual: imagen original, máscara real multicategoría y predicción del modelo para un caso con predominio de arrugas.}}{128}{figure.caption.81}%
\contentsline {figure}{\numberline {67}{\ignorespaces Comparación visual: ejemplo donde se observa el desempeño del modelo en la detección de manchas, destacando regiones correctamente identificadas y algunas áreas faltantes.}}{128}{figure.caption.82}%
\contentsline {figure}{\numberline {68}{\ignorespaces Comparación visual: caso mixto donde se presentan simultáneamente arrugas y manchas, mostrando la capacidad del modelo para diferenciar ambas clases en un mismo rostro.}}{128}{figure.caption.83}%
\contentsline {figure}{\numberline {69}{\ignorespaces Evaluación del U-Net con codificador MiT-B0}}{129}{figure.caption.84}%
\contentsline {figure}{\numberline {70}{\ignorespaces Comparación visual: imagen original, máscara real multicategoría y predicción del modelo para un caso con predominio de manchas.}}{131}{figure.caption.85}%
\contentsline {figure}{\numberline {71}{\ignorespaces Comparación visual: ejemplo donde se observa el desempeño del modelo en la detección de manchas, destacando pocas regiones correctamente identificadas y la mayoría de áreas faltantes.}}{131}{figure.caption.86}%
\contentsline {figure}{\numberline {72}{\ignorespaces Comparación visual: ejemplo donde se observa el desempeño del modelo en la detección de manchas, destacando casi ninguna de las regiones correctamente identificadas y muchas áreas faltantes.}}{132}{figure.caption.87}%
\contentsline {figure}{\numberline {73}{\ignorespaces Evaluación del Mask R-CNN}}{132}{figure.caption.88}%
\contentsline {figure}{\numberline {74}{\ignorespaces Comparación visual: imagen original, máscara real multicategoría y predicción del modelo 1.}}{134}{figure.caption.89}%
\contentsline {figure}{\numberline {75}{\ignorespaces Comparación visual: imagen original, máscara real multicategoría y predicción del modelo 2.}}{134}{figure.caption.90}%
\contentsline {figure}{\numberline {76}{\ignorespaces Presentación inicial de la página.}}{138}{figure.caption.92}%
\contentsline {figure}{\numberline {77}{\ignorespaces Presentación con cámara activa.}}{138}{figure.caption.93}%
\contentsline {figure}{\numberline {78}{\ignorespaces Presentación de la segmentación.}}{139}{figure.caption.94}%
\contentsline {figure}{\numberline {79}{\ignorespaces Presentación cuando no hay un rostro.}}{139}{figure.caption.95}%
\contentsline {figure}{\numberline {80}{\ignorespaces Presentación cuando el rostro no está en el centro.}}{140}{figure.caption.96}%
