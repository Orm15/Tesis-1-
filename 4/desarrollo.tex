\chapter{Desarrollo de la Solución}
Dentro de esta sección se expone con precisión el procedimiento descrito previamente en la sección anterior, correspondiente a cada acción incluida en la metodología implementada, junto con los entregables previstos.

\section{Adquisición de los Datos}

\textbf{Actividad 1: Identificación de la data que contengan imágenes de rostros con características morfológicas faciales de proporciones similares}
 
Con el objetivo de entrenar un modelo de segmentación enfocado en características morfológicas faciales como arrugas y manchas, se llevó a cabo una exhaustiva búsqueda de bases de datos públicas en repositorios especializados. Se priorizó la recolección de conjuntos de datos que incluyeran imágenes faciales en alta resolución, variedad de edades, géneros y tonos de piel, así como condiciones de iluminación lo suficientemente controladas como para facilitar la segmentación de detalles faciales sutiles.

Durante este proceso, se identificaron diversos repositorios en plataformas como GitHub que ofrecían acceso a bases de datos con más de 200,000 imágenes faciales. Entre los conjuntos más destacados se encuentran versiones extendidas de datasets como CelebA, FFHQ (Flickr-Faces-HQ), y otros compendios curados por la comunidad investigadora, que contienen imágenes faciales etiquetadas o anotadas para tareas de reconocimiento y análisis facial.

Sin embargo, debido al enfoque específico de esta investigación la segmentación de características morfológicas finas como arrugas y manchas fue necesario realizar una selección cuidadosa de las imágenes más adecuadas. Para ello, se aplicaron criterios de claridad visual, resolución suficiente y visibilidad explícita de las deformaciones morfológicas faciales. Como resultado de este filtrado, se seleccionó un subconjunto compuesto por 5,000 imágenes faciales que cumplían con los siguientes criterios:

\begin{itemize}
    \item Alta calidad visual.   
    \item Visibilidad clara de texturas de la piel.
    \item Presencia evidente de arrugas y manchas.
    \item Proporciones faciales dentro de un rango estándar para facilitar el modelado.
\end{itemize} 

Este conjunto reducido pero representativo,lo podemos ver en la Figura \ref{4:fig1}, constituye la base de entrenamiento y validación del modelo propuesto. La selección manual de estos datos buscó optimizar el desempeño del modelo, al exponerlo exclusivamente a ejemplos que contienen información útil para aprender patrones asociados a las características morfológicas de interés.

\begin{figure}[h]
	\begin{center}
		\includegraphics[width=0.75\textwidth]{4/figures/data.png}
		\caption[Dataset recolectado de repositorios]{Dataset recolectado de repositorios.\\
		Fuente: Elaboración propia}
		\label{4:fig1}
	\end{center}
\end{figure}

\section{Preprocesamiento de los Datos}

\textbf{Actividad 1: Filtración de imágenes faciales con características morfológicas}

Una vez recopilado el subconjunto de 5,000 imágenes faciales con características morfológicas visibles, se procedió a una etapa de filtración adicional orientada a reforzar la consistencia y la relevancia de los datos para la tarea de segmentación. Esta filtración se enfocó en garantizar que todas las imágenes seleccionadas contuvieran arrugas y manchas claramente identificables, descartando aquellas que, pese a su calidad visual, no presentaban estas características de manera explícita.

El proceso se realizó mediante una inspección semiautomática, apoyada en técnicas básicas de detección de texturas y realce de bordes para facilitar la identificación visual de las zonas con deformaciones. Como resultado, se aseguraron condiciones homogéneas entre las imágenes del dataset final, lo que permitió una base sólida para la generación de máscaras de segmentación precisas.

\textbf{Actividad 2: Representación y normalización de las imágenes faciales}

Con el conjunto de imágenes definitivo, se ejecutó un proceso de preprocesamiento estandarizado con dos objetivos principales: uniformar las dimensiones espaciales de las imágenes y generar las máscaras binarias asociadas a las regiones con deformaciones morfológicas.

En primer lugar, todas las imágenes fueron redimensionadas a una resolución uniforme de 1024x1024 píxeles, preservando la relación de aspecto y aplicando interpolación bilineal para mantener la calidad visual. Esta estandarización es fundamental para asegurar la compatibilidad estructural con las redes neuronales convolucionales utilizadas en etapas posteriores, y facilita la aplicación de operaciones convolucionales sobre áreas homogéneas.

En segundo lugar, se generaron máscaras binarias (en blanco y negro) correspondientes a cada imagen. Estas máscaras representan las regiones específicas del rostro que contienen arrugas, manchas u otras alteraciones morfológicas, codificadas de la siguiente manera:

\begin{itemize}
    \item Blanco (valor 1): Regiones con características morfológicas relevantes (objetivo de segmentación).   
    \item Negro (valor 0): Regiones sin interés morfológico.
\end{itemize} 

Las máscaras, como se ve en la Figura \ref{4:fig2}, fueron elaboradas a partir de una combinación de anotación semiautomática y herramientas de realce de texturas, contrastes y gradientes, con verificación manual en una muestra aleatoria para asegurar su validez.

\begin{figure}[h]
	\begin{center}
		\includegraphics[width=0.75\textwidth]{4/figures/mascaras.png}
		\caption[Máscaras binarias generadas]{Máscaras binarias generadas.\\
		Fuente: Elaboración propia}
		\label{4:fig2}
	\end{center}
\end{figure}

Este proceso de representación y normalización, como se ve en el diagrama final de Preprocesamiento en la Figura \ref{4:fig3}, permitió convertir los datos originales en pares de entrada (imagen facial) y salida (máscara de segmentación), aptos para el entrenamiento supervisado del modelo de segmentación basado en redes neuronales convolucionales.

\begin{figure}[h]
	\begin{center}
		\includegraphics[width=0.75\textwidth]{4/figures/diagrama final prepo.png}
		\caption[Diagrama de Preprocesamiento Utilizado]{Diagrama de Preprocesamiento Utilizado.\\
		Fuente: Elaboración propia}
		\label{4:fig2}
	\end{center}
\end{figure}

\section{Desarrollo de los Modelos de Segmentación}

\textbf{Actividad 1: Diseño de la arquitectura del modelo}\\
Se diseñó una arquitectura basada en U-Net con Attention Gates, que consta de:
\begin{itemize}
  \item Módulos de doble convolución (DoubleConv) en el encoder y decoder.  
  \item Capas de atención (AttentionGate) ubicadas en cada salto del decoder para realzar las regiones de interés (arrugas y manchas).  
  \item Caminos de downsampling (MaxPool2d) y upsampling (ConvTranspose2d) para conservar la resolución espacial.  
  \item Capa final de convolución 1x1 para segmentación en tres clases (fondo, arrugas, manchas).  
\end{itemize}

\textbf{Actividad 2: Definición de componentes del modelo}\\
Los componentes principales incluyen:
\begin{itemize}
  \item \textit{DoubleConv}: bloque de dos convoluciones secuenciales con BatchNorm y ReLU.  
  \item \textit{AttentionGate}: mecanismo de atención consistente en convoluciones 1x1, sumas tensoriales y función Sigmoid para generar máscaras atencionales.  
  \item Optimizador \texttt{AdamW} con decaimiento de pesos para mejorar la generalización.  
  \item Scheduler \texttt{ReduceLROnPlateau} para ajuste dinámico de la tasa de aprendizaje.  
  \item Función de pérdida \texttt{CrossEntropyLoss} con pesos calculados por median frequency balancing.  
\end{itemize}

\textbf{Actividad 3: Estrategia de ensamblado del modelo}\\
Se definió una estrategia de ensamblado simple basada en el entrenamiento de un solo modelo entrenado por 50 épocas, guardando el estado de mejor rendimiento en validación (menor pérdida). No se implementó ensamblado múltiple, pues la arquitectura con atención demostró ser suficiente tras el análisis de métricas.

\section{Entrenamiento del Modelo}

\textbf{Actividad 1: Configuración del entorno de entrenamiento}\\
Se configuró el entorno con los siguientes parámetros:
\begin{itemize}
  \item Ruta de datos: \texttt{face\_images}, \texttt{arrugas}, \texttt{manchas}.  
  \item Tamaño de lote (batch size): 4.  
  \item Dimensión de entrada: 256 x 256 píxeles.  
  \item Tasa de aprendizaje inicial: $1\times10^{-4}$.  
  \item Número de épocas: 50.  
  \item Dispositivo de cómputo: GPU (CUDA) o CPU según disponibilidad.  
  \item Semilla aleatoria fija (42) para reproducibilidad.  
\end{itemize}

\textbf{Actividad 2: Aplicación de técnicas de optimización}\\
Se incorporaron las siguientes técnicas:
\begin{itemize}
  \item Aumentos de datos con \texttt{albumentations}: volteos, rotaciones, ruido Gaussiano, brillo/contraste, transformaciones elásticas y desenfoque.  
  \item Balanceo de clases mediante median frequency balancing para generar pesos en \texttt{CrossEntropyLoss}.  
  \item Optimizador \texttt{AdamW} y scheduler \texttt{ReduceLROnPlateau} para ajuste automático de la tasa de aprendizaje.  
  \item Impresión de métricas de pérdida en entrenamiento y validación por época.  
\end{itemize}

\textbf{Actividad 3: Validación cruzada del rendimiento}\\
La validación se realizó con:
\begin{itemize}
  \item División de datos: 80\% entrenamiento, 20\% validación usando \texttt{train\_test\_split}.  
  \item DataLoaders separados para entrenamiento y validación, garantizando evaluación independiente.  
  \item Cálculo de métricas (pérdida, precisión, Dice, Jaccard) en el conjunto de validación cada época.  
  \item Guardado del modelo con menor \emph{val\_loss} como mejor checkpoint.  
\end{itemize}


\section{Evaluación del Modelo}

\textbf{Actividad 1: Preparación de Datos de Validación}\\
Se prepararon las imágenes de validación con transformaciones mínimas:
\begin{itemize}
  \item Redimensionamiento a 256x256 píxeles.  
  \item Conversión a tensor SIN alteraciones adicionales.  
  \item Unión de máscaras de arrugas y manchas en una única máscara multicategoría.  
\end{itemize}

\textbf{Actividad 2: Definición de Métricas de Evaluación}\\
Las métricas utilizadas fueron:
\begin{itemize}
  \item \textit{Precision} (macro) para evaluar la exactitud de las predicciones.  
  \item \textit{Dice Score} promedio para medir la superposición.  
  \item \textit{Jaccard Index (IoU)} promedio para una evaluación estricta del solapamiento.  
\end{itemize}

\textbf{Actividad 3: Evaluación del Modelo}\\
El modelo alcanzó los siguientes resultados en validación:
\begin{itemize}
  \item \textbf{Pérdida mínima (val\_loss):} 0.0458 (época 50).  
  \item \textbf{Precision promedio:} 0.645.  
  \item \textbf{Dice Score promedio:} 0.440.  
  \item \textbf{Jaccard Index promedio:} 0.289.  
  \item Se observaron mejores resultados en la detección de arrugas debido a mayor representación de esta clase.  
  \item La clase ":manchas" mostró métricas ligeramente inferiores, sugiriendo futuras mejoras en aumentos específicos.  
\end{itemize}

Los resultados numéricos y ejemplos de segmentaciones se presentan en la sección de análisis de resultados con gráficas de evolución y comparaciones visuales.


\section{Despliegue}

\textbf{Actividad 1: Preparación del Entorno de Despliegue}

\textbf{Actividad 2: Despliegue del Modelo en Producción}
