\subsection{Inteligencia Artificial}

El método racional fusiona la ingeniería y las matemáticas basándose en las "leyes del pensamiento", las cuales tienen su origen en la antigua Grecia y han sido influenciadas por filósofos como Aristóteles. Durante el siglo XIX, se diseñaron programas capaces de resolver problemas de lógica. Por consiguiente, el propósito de la Inteligencia Artificial en la vida real es crear sistemas inteligentes que posean estas habilidades. Aun en situaciones de incertidumbre, un "Agente Racional" toma acciones con el fin de obtener el mejor resultado posible. La inteligencia artificial se apoya en diversas disciplinas, tales como la ingeniería computacional, la teoría de control, la cibernética, la lingüística, la filosofía, la economía, la psicología, la neurociencia y las matemáticas, de acuerdo con \cite{bk_russell2004intart}.

Dos investigadores en neurociencia crearon el primer modelo de IA basado en neuronas artificiales en 1943, dando inicio al análisis de la Inteligencia Artificial. McCulloch y Pitts idearon el prototipo que permitía que las neuronas fueran <<activadas>> o <<desactivadas>>, lo que demostró que una red de neuronas era capaz de realizar cualquier tarea computacional. Posteriormente, Donald Hebb propuso la <<Regla de Aprendizaje Hebbiano>>. John McCarthy, Allen Newell y Herbert Simon desarrollaron un programa que podía tener el pensamiento no numérico en el taller de Dartmouth, aunque no se publicó. El término <<Inteligencia Artificial>> fue acuñado por McCarthy, \parencite{bk_russell2004intart}.

La IA comenzó a entrar en la industria en los años 80, especialmente en grandes empresas de países desarrollados, a través de la investigación en sistemas expertos y el desarrollo de computadoras más poderosas.

\subsection{Aprendizaje Automático}
El Machine Learning es un área de la Inteligencia Artificial enfocada en técnicas que permiten a las computadoras aprender a través de algoritmos, convirtiendo muestras de datos en programas sin requerir programación explícita. Según \cite{bk_russell2009intart}, el aprendizaje automático es una división de la inteligencia artificial. Estos algoritmos emplean tecnologías como el procesamiento del lenguaje natural, el aprendizaje profundo y las redes neuronales. Tanto el aprendizaje supervisado como el no supervisado se fundamentan en lecciones extraídas de los datos. La creación de algoritmos capaces de recibir datos de entrada y utilizar análisis estadístico para prever una salida, la cual se ajusta conforme se obtienen nuevos datos, constituye el fundamento del aprendizaje automático \cite{bk_alpaydin2014ml}.

Se puede clasificar en cuatro tipos principales de la siguiente manera según el objetivo que se desea alcanzar mediante el uso de ML:
\begin{itemize}
	\item \textbf{Aprendizaje Supervisado}: El Aprendizaje Supervisado se ganó su nombre porque los científicos de datos actúan como una guía para enseñarle al algoritmo las conclusiones a las que debe llegar. Es similar a la forma en que un estudiante aprende aritmética básica de un maestro. Este tipo de aprendizaje requiere datos etiquetados con las respuestas correctas que se esperan del resultado del algoritmo. Para problemas de clasificación y regresión, el aprendizaje supervisado demostró ser preciso y rápido según \parencite{bk_zambrano2018supnosup}.
	
	Los dos tipos de Aprendizaje Supervisado son:

	\begin{itemize}
		\item \textbf{La Clasificación}: es la predicción del valor categórico de salida que permite dividir los datos en clases específicas. La clasificación se puede usar para varios propósitos, como determinar el clima, determinar si un correo electrónico es spam o no o identificar tipos de animales después de recibir una educación adecuada, un conjunto de datos con etiquetas de imágenes que incluyen la especie y algunas identificaciones características, según \parencite{bk_zambrano2018supnosup}.
		\item \textbf{La Regresión}: es un tipo de problema en el que la predicción de un valor de respuesta continua es necesaria, como los precios de las acciones y la vivienda, según \parencite{bk_zambrano2018supnosup}.
	\end{itemize}

	Por lo tanto, funciona modelando las relaciones y dependencias entre las características de entrada y la salida de predicción objetivo, lo que permite predecir los valores de salida para nuevos datos utilizando las relaciones que aprendió de conjuntos de datos anteriores, según \parencite{bk_alpaydin2014ml}.

	\item \textbf{Aprendizaje No Supervisado}: Por otro lado, el Aprendizaje No Supervisado se asemeja más a lo que algunos expertos llaman Inteligencia Artificial real: la idea de que una máquina puede aprender a identificar patrones y procesos complejos sin la supervisión de humanos. Cuando los expertos no saben qué buscar en los datos y los datos en sí no incluyen objetivos, este método es particularmente útil. La agrupación de k-means, el análisis de componentes principales e independientes y las reglas de asociación según \parencite{bk_zambrano2018supnosup} son algunos de los muchos casos de uso del Aprendizaje Automático No Supervisado.
	
	\begin{itemize}
		\item \textbf{Agrupación K-means}: es un tipo de problema en el que cosas similares están agrupadas, como se muestra en la Figura \ref{2:fig33}. Comparte el mismo concepto con la clasificación, pero no se proporcionan etiquetas, por lo que el sistema entenderá los datos y los agrupará. Un uso de esto sería agrupar los artículos y las noticias según su género y contenido, según \parencite{tec_sancho2018supnosup}
	\end{itemize}
	
		\begin{figure}[h]
		\begin{center}
			\includegraphics[width=0.75\textwidth]{2/figures/kmeans.png}
			\caption[El algoritmo de K medias]{El algoritmo de K medias.\\
			Fuente: \cite{tec_sancho2018supnosup}. \citetitle{tec_sancho2018supnosup}.}
			\label{2:fig33}
		\end{center}
	\end{figure}
		
	Debido a su complejidad y dificultad de implementación, este tipo de Aprendizaje Automático no se utiliza tan frecuentemente como el Aprendizaje Supervisado, a pesar de que abre las puertas a la resolución de problemas que los humanos normalmente no abordarían, según \parencite{tec_sancho2018supnosup}

	\item \textbf{Aprendizaje Semisupervisado}: Hasta el momento, todos los datos enviados han sido etiquetados con el resultado deseado o no han sido etiquetados en absoluto. El Aprendizaje Automático Semisupervisado utiliza ambos. El costo de etiquetar es bastante alto en muchas situaciones prácticas y, en el caso de grandes conjuntos de datos, se vuelve aburrido y requiere mucho tiempo. Además, proporcionar demasiados datos etiquetados puede hacer que el modelo tenga sesgos humanos. A pesar de que los datos sin etiquetar son desconocidos para la red, ofrecen información útil sobre los parámetros del grupo objetivo. que conduce a la conclusión de que se puede mejorar la precisión del modelo al incluir datos sin etiquetar y, al mismo tiempo, ahorrar tiempo y dinero en su construcción. Por ejemplo, la clasificación de páginas web, el reconocimiento de voz o la secuenciación genética pueden usar Aprendizaje Automático Semisupervisado. En esos casos, los científicos de datos pueden acceder a grandes cantidades de datos sin etiquetarlos, y la tarea de etiquetarlos todos llevaría mucho tiempo, según \parencite{bk_zambrano2018supnosup}.

	Se puede comparar estos tres tipos de Aprendizaje Automático para el mismo uso, como clasificación, utilizando los datos recopilados hasta ahora:

	\begin{itemize}
		\item \textbf{Clasificación supervisada}: el algoritmo clasificará los tipos de páginas web según las etiquetas proporcionadas desde el principio, según \parencite{bk_zambrano2018supnosup}.
		\item \textbf{Agrupación no supervisada}: el algoritmo buscará patrones y características que ayudan a agrupar páginas web en grupos, según \parencite{bk_zambrano2018supnosup}.
		\item \textbf{Clasificación semi no supervisada}: identificará varios grupos de páginas web utilizando los datos etiquetados, luego utilizará los datos no etiquetados para establecer los límites de esos grupos de páginas web y buscar otros tipos que posiblemente no aparezcan en los datos etiquetados, según \parencite{bk_zambrano2018supnosup}.
	\end{itemize}
	
\end{itemize}

\subsection{Aprendizaje Profundo}

Desde que llegó la Inteligencia Artificial hace un tiempo, tiene una amplia gama de aplicaciones y se divide en muchas ramas, como se menciona en \parencite{gl_sas_deeplearning}. El Aprendizaje Profundo es un subconjunto del Aprendizaje Automático, que es en sí mismo un subcampo de la IA. La Figura \ref{2:fig55} es una representación visual de la relación entre AI, ML y DL.

\begin{figure}[!ht]
	\begin{center}
		\includegraphics[width=0.50\textwidth]{2/figures/deeplearning_machinelearning.jpg}
		\caption[Relación entre IA, ML y DL]{Relación entre IA, ML y DL.\\
		Fuente: \cite{tec_cook2018deeplearning}. \textit{Most Popular 20 Free Online Courses to Learn Deep Learning}.}
		\label{2:fig55}
	\end{center}
\end{figure}

El Aprendizaje Profundo no solo permite representar datos de la manera correcta, sino que también permite que la computadora aprenda programas informáticos de varios pasos al incluir el concepto de profundidad en sus modelos. Como se muestra en la Figura \ref{2:fig56}, cada capa de representación puede interpretarse como el estado de la memoria de la computadora. Las computadoras interpretan las imágenes como una colección de valores de píxeles que representan escenas de nuestra realidad. Según \parencite{tec_cook2018deeplearning}, identificar un objeto o mapear su identidad a partir de esos valores es una tarea difícil para las máquinas y puede resultar casi imposible cuando se intenta aprender este mapeo directamente.

\begin{figure}[!ht]
	\begin{center}
		\includegraphics[width=0.70\textwidth]{2/figures/deeplearning_machinelearning2.jpg}
		\caption[Modelo de aprendizaje profundo]{Modelo de aprendizaje profundo.\\
		Fuente: \cite{tec_cook2018deeplearning}. \textit{Most Popular 20 Free Online Courses to Learn Deep Learning}.}
		\label{2:fig56}
	\end{center}
\end{figure}


\subsection{Aprendizaje Profundo Multimodal}
Podemos ver en la Figura \ref{2:fig57}, el fundamento del Aprendizaje Profundo Multimodal es la integración de diversas modalidades a través del uso de redes neuronales profundas. \parencite{bk_deng2018deeplearningnlp}.

\begin{figure}[!ht]
	\begin{center}
		\includegraphics[width=0.85\textwidth]{2/figures/multimodal_network.png}
		\caption[Modelo que combina imágenes y texto]{Modelo que combina imágenes y texto.\\
		Fuente: \cite{tec_nishida2015multimodal}. \textit{Multimodal gesture recognition using multi-stream recurrent neural network}.}
		\label{2:fig57}
	\end{center}
\end{figure}

Las señales provenientes de distintas fuentes brindan datos adicionales sobre diferentes aspectos de un tema, lo cual capacita a los métodos que emplean varias técnicas para efectuar inferencias más sólidas. En el ámbito de las técnicas multimodales existen diversas estrategias como las estrategias de integración y combinación, los sistemas computacionales, el proceso de unir diferentes modelos y las estructuras de redes neuronales con múltiples capas. Al combinar estas características para la toma de decisiones, se emplean enfoques aditivos que recopilan información relevante y mejoran conjuntamente la precisión de las predicciones \cite{bk_deng2018deeplearningnlp}.

\cite{tec_baheti2020introduction_mdl} afirman que el uso de modelos multimodales mejora el rendimiento de las redes neuronales y permite una extracción más efectiva de características, lo que favorece predicciones mayores. Uno de las ventajas es que los datos de diferentes fuentes ofrecen información complementaria que revela patrones ocultos que no se pueden ver cuando las modalidades se analizan individualmente, mejorando así la precisión de las predicciones.

Según \cite{tec_brownlee2018stacked_models}, se puede mejorar la calidad del promedio del modelo al considerar de manera ponderada las aportaciones individuales de cada submodelo a la predicción global. Este enfoque se conoce como <<generalización apilada>> y se divide en dos niveles.

\begin{itemize}
    \item Nivel 0: Este nivel utiliza los datos de entrada del conjunto de entrenamiento para enseñar a los modelos a hacer predicciones.
    \item Nivel 1: Aquí, los datos provienen de las salidas de los modelos del nivel anterior, que se utilizan como entradas para instruir a los modelos en esta etapa, también conocidos como meta-aprendices o generalizadores.
\end{itemize}

En el contexto de los modelos apilados, se utilizan dos métodos diferentes:

\begin{itemize}
    \item Enfoque de apilamiento por separado: Implica crear los datos de entrada conjuntos utilizando los pronósticos amalgamados de modelos adicionales. Estos datos se emplean para instruir a un modelo extra que realiza la predicción final.
	\item Modelo apilado integrado: Esta estrategia facilita la utilización de arquitecturas neuronales y un modelo de múltiples cabezas conformado por otros modelos preentrenados. Estos modelos no requieren conservar la misma configuración, dado que sus niveles se etiquetancomo "no susceptibles al entrenamiento" para prevenir la modificación de sus valores antes de efectuar predicciones. Las salidas de los submodelos se fusionan directamente en el modelo principal.
\end{itemize}

\begin{figure}[!ht]
	\begin{center}
		\includegraphics[width=0.79\textwidth]{2/figures/multimodal_deep_learning_example.jpg}
		\caption[Un modelo multimodal para las señales de la vista]{Un modelo multimodal para las señales de la vista.\\
		Fuente: \cite{tec_baheti2020introduction_mdl}. \citetitle{tec_baheti2020introduction_mdl}.}
		\label{2:fig58}
	\end{center}
\end{figure}

\subsection{Inteligencia Artificial Generativa}

La Inteligencia Artificial Generativa es el campo de la ciencia que estudia cómo crear inteligencia totalmente automatizada. Esto contrasta con el campo de la Inteligencia Artificial Moderna, que investiga cómo los humanos comprenden y construyen la inteligencia. La construcción manual es lo que hacen los investigadores, pero la parte <<por humanos>> de la definición de IA suele ser una variable oculta en la construcción de los sistemas de IA contemporáneos. Aunque la diferencia puede parecer sutil, incluso innecesaria, la construcción automatizada requiere una perspectiva completamente nueva, que no está disponible en la literatura sobre IA actual. No importa si los humanos comprenden cómo funcionan los mecanismos internos de una máquina en la Inteligencia Artificial Generativa, aunque podría ayudar a los investigadores en su búsqueda de la creación de máquinas inteligentes. Lo que importa es que la máquina pueda controlar y dirigir el proceso de creación de estructuras internas en la dirección deseada. Es como criar hijos: los seres humanos no son conscientes de los procesos mentales, pero interactúan con sus hijos en un nivel diferente al hablar de sus sustratos neuronales. En lugar de eso, utilizan una variedad de máquinas clasificadoras para diferenciar los comportamientos positivos de los negativos, que podrían ser beneficiosos para el niño cuando sea mayor. Los castigos corporales, los institutos educativos, los medios de comunicación y otros lugares son algunos de los usos de estas máquinas clasificadoras, según \parencite{th_zant2010genai}

A continuación, ofrecemos una variedad de categorías de modelos de Inteligencia Artificial Generativa.

\begin{itemize}
	\item \textbf{Modelos de difusión}: crean nuevos datos iterando cambios aleatorios controlados en una muestra de datos previa. Empezan con los datos originales y luego agregan cambios sutiles, también conocidos como ruido, que hacen que gradualmente pierdan la similitud con el original. Este ruido se controla minuciosamente para garantizar que los datos generados sigan siendo consistentes y realistas. El modelo de difusión invierte el proceso después de agregar ruido en varias iteraciones. Como se muestra en la Figura \ref{2:fig59}, la eliminación de ruido inversa crea una muestra de datos nueva que se asemeja a la original, según \parencite{tec_amaz2023iagen}.
	
	\begin{figure}[!ht]
		\begin{center}
			\includegraphics[width=0.85\textwidth]{2/figures/modelosdedifusion.jpg}
			\caption[Modelos de difusión]{Modelos de difusión.\\
			Fuente: \cite{tec_amaz2023iagen}. \citetitle{tec_amaz2023iagen}.}
			\label{2:fig59}
		\end{center}
	\end{figure}

	\item \textbf{Redes generativas adversativas}: compiten con dos redes neuronales. La primera red, también conocida como generador, agrega ruido aleatorio para crear muestras de datos falsas. La segunda red, conocida como discriminador, ayuda a distinguir entre los datos reales y falsos generados por el generador. El generador mejora continuamente su capacidad de generar datos realistas, mientras que el discriminador mejora su capacidad de distinguir entre lo real y lo falso. Hasta que el generador produzca datos tan persuasivos que el discriminador no pueda diferenciarlos de los datos reales, este proceso adversativo termina, según \parencite{tec_amaz2023iagen}.

	\item \textbf{Autocodificadores variacionales}: aprenden sobre el espacio latente, una pequeña representación de datos. La representación matemática de los datos se conoce como espacio latente. Puede verse como un código único que representa los datos en función de cada característica. Por ejemplo, cuando se estudian los rostros, el espacio latente contiene números que representan la forma de las orejas, los pómulos, la nariz y los ojos. Las dos redes neuronales utilizadas por los VAE son el codificador y el decodificador. Para cada dimensión del espacio latente, la red neuronal del codificador mapea los datos de entrada a una media y una varianza. crea una muestra aleatoria utilizando la distribución normal gaussiana. Este ejemplo es un punto en el espacio latente, y como se puede ver en la Figura \ref{2:fig60}, representa una versión comprimida y simplificada de los datos de entrada, según \parencite{tec_amaz2023iagen}.
	
	\begin{figure}[!ht]
		\begin{center}
			\includegraphics[width=0.85\textwidth]{2/figures/autocodificadoresvariacionales.png}
			\caption[Autocodificadores variacionales]{Autocodificadores variacionales.\\
			Fuente: \cite{tec_amaz2023iagen}. \citetitle{tec_amaz2023iagen}.}
			\label{2:fig60}
		\end{center}
	\end{figure}
\end{itemize}


\subsection{Segmentación de Imágenes}
%%%%%%%%
\subsubsection{Definición y objetivos de la segmentación de imágenes}
La segmentación de imágenes es un proceso fundamental en el campo del procesamiento de imágenes y la visión por computadora, cuyo propósito es dividir una imagen en partes significativas y coherentes, facilitando su análisis e interpretación. Este proceso busca simplificar la representación de una imagen, destacando las regiones de interés o los objetos específicos que contiene, separándolos del fondo y otras áreas irrelevantes \parencite{gonzalez2018}.

Los objetivos principales de la segmentación incluyen identificar, clasificar y delimitar regiones u objetos dentro de una imagen. En aplicaciones prácticas, estos objetivos son cruciales, ya que permiten resolver problemas como la detección de bordes, la identificación de patrones, la localización de estructuras específicas y el análisis morfológico. En el ámbito médico, por ejemplo, la segmentación de imágenes se utiliza para identificar tejidos, órganos o anomalías, como tumores o lesiones. De manera similar, en la industria cosmética, este proceso puede emplearse para detectar características faciales como arrugas, poros y manchas, ayudando en la evaluación estética y la personalización de tratamientos \parencite{gonzalez2018}.

Existen múltiples técnicas para la segmentación, que van desde enfoques tradicionales como la segmentación basada en umbrales, el análisis de regiones y la detección de bordes, hasta métodos avanzados como las redes neuronales convolucionales (CNN). Estas últimas han revolucionado el campo al permitir segmentaciones más precisas y automáticas, especialmente en imágenes complejas donde las características pueden ser sutiles o con variaciones significativas en color, textura y forma. Por ello, la segmentación es un paso esencial en cualquier flujo de trabajo que involucre el análisis de imágenes, proporcionando una base sólida para tareas más avanzadas de procesamiento y análisis \parencite{gonzalez2018}.
%%%%%%
\subsubsection{Importancia de la segmentación en aplicaciones médicas y cosméticas}
En el ámbito médico y cosmético, la segmentación precisa de imágenes juega un papel crucial al permitir que los profesionales de la salud y la belleza realicen evaluaciones más detalladas y personalizadas de las condiciones dermatológicas. Este proceso facilita la identificación y el análisis de características específicas de la piel, lo que es fundamental para detectar anomalías y personalizar los tratamientos de acuerdo con las necesidades individuales de los pacientes o clientes. La segmentación es particularmente importante en el diagnóstico de enfermedades de la piel, donde la capacidad de identificar y analizar estructuras o patrones morfológicos específicos puede mejorar significativamente la precisión del diagnóstico.

Por ejemplo, en dermatología, la segmentación adecuada de imágenes faciales permite identificar con mayor precisión imperfecciones cutáneas como manchas, arrugas y poros dilatados. Estos elementos son indicadores comunes de diversas afecciones dermatológicas, como el envejecimiento prematuro, las manchas solares o los trastornos hormonales. De igual manera, en la industria cosmética, la segmentación de características faciales es esencial para el diseño de tratamientos personalizados, ayudando a los profesionales a ofrecer soluciones más efectivas que aborden las preocupaciones estéticas específicas de cada cliente.

El uso de técnicas avanzadas de segmentación, como las redes neuronales convolucionales (CNN), ha revolucionado el campo, permitiendo una segmentación más precisa y automatizada, incluso en casos complejos donde las características de la piel pueden ser sutiles o variar en color, textura o forma. La segmentación no solo mejora la detección de condiciones dermatológicas, sino que también optimiza la personalización de tratamientos cosméticos, ya que permite que los productos sean aplicados de manera más eficiente, dirigiéndose específicamente a las áreas que requieren intervención. Esto puede resultar en un mejor rendimiento de los productos cosméticos, mayor satisfacción del cliente y, en última instancia, en una mejora de la salud de la piel.

En resumen, la segmentación de imágenes en el ámbito médico y cosmético no solo mejora la capacidad de diagnóstico, sino que también facilita la personalización de tratamientos, mejorando la efectividad y la satisfacción de los pacientes o clientes \cite{mohammadi2019}.
%%%%%%%%%
\subsubsection{Técnicas de segmentación clásicas y sus limitaciones en imágenes dermatológicas}
Las técnicas clásicas de segmentación, como el umbralizado y la detección de bordes, han sido fundamentales en los primeros enfoques de procesamiento de imágenes. Estas técnicas buscan dividir la imagen en regiones homogéneas basadas en características como el color, la intensidad de los píxeles o los bordes de los objetos. Sin embargo, en el contexto dermatológico, estas técnicas presentan limitaciones significativas debido a la complejidad y variabilidad inherente de las imágenes de la piel.

Una de las técnicas clásicas más utilizadas es el \textit{umbralizado}, que divide una imagen en dos o más regiones basadas en el valor de intensidad de los píxeles. Esta técnica es eficiente cuando los objetos a segmentar se destacan claramente del fondo. Sin embargo, en imágenes dermatológicas, la piel tiene una amplia gama de tonalidades y texturas que varían entre diferentes personas, lo que puede dificultar la aplicación de umbrales estáticos que funcionen de manera efectiva en todos los casos. Además, las variaciones en la iluminación y la presencia de sombras en la piel pueden afectar negativamente el rendimiento del umbralizado, llevando a una segmentación incorrecta de las áreas de interés, como las arrugas, manchas o poros.

La \textit{detección de bordes}, otra técnica clásica, se utiliza para identificar discontinuidades en la imagen, donde los bordes de los objetos se encuentran con un contraste significativo con el fondo. Técnicas como el operador de Sobel o el Canny se han utilizado para detectar bordes en imágenes de la piel. Sin embargo, los bordes de las características cutáneas no siempre están claramente definidos. La piel puede tener bordes suaves o difusos, especialmente cuando se trata de características como manchas o líneas finas. Esto hace que la detección de bordes sea menos efectiva para segmentar detalles sutiles en la piel, lo que limita su capacidad para proporcionar una segmentación precisa.

Estas técnicas clásicas también presentan dificultades cuando se enfrentan a características dermatológicas con variaciones complejas en la textura y el color de la piel. Por ejemplo, las manchas pueden tener bordes poco definidos, y las arrugas pueden ser de diferente grosor y profundidad. Además, las características morfológicas de la piel, como los poros dilatados o las arrugas finas, pueden tener formas irregulares que no se ajustan bien a las suposiciones que estas técnicas clásicas requieren. Las técnicas basadas en umbrales o en la detección de bordes también son sensibles al ruido y pueden ser ineficaces al trabajar con imágenes con poca calidad o cuando las características de la piel tienen un contraste bajo con el fondo.

Debido a estas limitaciones, las técnicas clásicas de segmentación no siempre son adecuadas para aplicaciones dermatológicas de alta precisión. Aunque siguen siendo útiles en ciertos contextos, su capacidad para segmentar con precisión detalles finos en la piel es insuficiente cuando se requiere una segmentación detallada y robusta. Es por esto que, en los últimos años, las técnicas más avanzadas, como las redes neuronales convolucionales (CNN), han comenzado a ganar popularidad en el campo de la dermatología y la cosmética, ofreciendo una solución más precisa y automática para la segmentación de características morfológicas complejas en la piel \parencite{yoo2020}.


\subsection{Redes Neuronales Convolucionales (CNN)}

Hoy en día, el procesamiento de imágenes, que incluye problemas de clasificación y visión por computadora, es una de sus aplicaciones más relevantes. El proyecto de Yann LeCun, ImageNet, utiliza el reconocimiento de objetos en imágenes.
	
	Estas redes también se utilizan para clasificar textos. Ronan Collobert y Jason Weston modificaron la arquitectura y los parámetros internos de las Redes Neuronales Convolucionales para usarlas en aplicaciones del PLN. La Figura \ref{2:fig40} muestra la estructura de una CNN para problemas de procesamiento de información natural. \parencite{bk_kamath2019deeplearning_nlp_sr}
	\begin{figure}[!ht]
		\begin{center}
			\includegraphics[width=0.95\textwidth]{2/figures/cnn_nlp.png}
			\caption[Arquitectura de un modelo CNN]{Arquitectura de un modelo CNN.\\
			Fuente: \cite{tec_kim2014convolutional}. \citetitle{tec_kim2014convolutional}. (p. 1747)}
			\label{2:fig40}
		\end{center}
	\end{figure}

\subsubsection{Arquitectura de las CNN: capas convolucionales, de pooling y totalmente conectadas}

Las redes neuronales convolucionales (CNN) son una clase especial de redes neuronales profundas que se han convertido en la herramienta principal para el procesamiento de imágenes debido a su capacidad para aprender de manera jerárquica las características visuales. La arquitectura de una CNN se compone principalmente de tres tipos de capas: \textbf{capas convolucionales}, \textbf{capas de pooling} y \textbf{capas totalmente conectadas}, cada una de las cuales cumple una función crucial en el proceso de análisis de imágenes.

\begin{itemize}
    \item \textbf{Capas convolucionales:} Estas son las encargadas de extraer características relevantes de la imagen, como bordes, texturas y formas. En cada capa convolucional, un filtro o "kernel" se desplaza a través de la imagen de entrada para realizar una operación de convolución, generando un mapa de características (feature map) que resalta los patrones presentes en las imágenes. A medida que se avanza a través de las capas, las CNN son capaces de aprender representaciones cada vez más complejas de las imágenes.
    
    \item \textbf{Capas de pooling:} Estas capas realizan un proceso de reducción de la dimensionalidad, cuyo objetivo es disminuir el tamaño de las características extraídas y, al mismo tiempo, conservar la información más importante. Esto se logra mediante operaciones como el \textit{max pooling}, donde se selecciona el valor máximo en un área específica de la imagen, o el \textit{average pooling}, que calcula el valor promedio. Las capas de pooling ayudan a reducir la cantidad de parámetros y la complejidad computacional del modelo, evitando el sobreajuste y mejorando la eficiencia.
    
    \item \textbf{Capas totalmente conectadas:} Después de las capas convolucionales y de pooling, las características extraídas se "aplanan" y se envían a través de una o varias capas totalmente conectadas. Estas capas son responsables de tomar las representaciones obtenidas en las capas anteriores y realizar la clasificación final. En una capa totalmente conectada, cada neurona está conectada a todas las neuronas de la capa anterior, lo que permite combinar las características extraídas para producir una salida.
\end{itemize}

Esta arquitectura jerárquica es especialmente efectiva para el procesamiento de imágenes, ya que las CNN son capaces de aprender de forma automática y eficiente las características de las imágenes a diferentes niveles de abstracción \parencite{krizhevsky2012}.

\subsubsection{Aplicación de CNN en segmentación de imágenes y su relevancia para la dermatología}
El uso de CNN en la segmentación de imágenes dermatológicas ha demostrado una mejora significativa en la precisión de diagnósticos. Estas redes son capaces de aprender patrones complejos y detalles sutiles que son esenciales para evaluar condiciones de la piel \cite{esteva2017}.

\subsubsection{Modelos avanzados de CNN para segmentación: U-Net, Fully Convolutional Networks (FCN)}
Modelos como U-Net y FCN han sido diseñados específicamente para la segmentación de imágenes. U-Net, por ejemplo, utiliza una arquitectura simétrica que permite una recuperación precisa de detalles en imágenes médicas \parencite{ronneberger2015}.

\subsection{Redes Generativas Adversariales (GANs)}  
Las Redes Generativas Adversariales (GANs) son una clase de redes neuronales que consisten en dos submodelos: un generador y un discriminador, que compiten entre sí para mejorar la calidad de los resultados generados. Las GANs han demostrado ser altamente efectivas en la generación de imágenes realistas y en tareas de segmentación, especialmente cuando los datos disponibles son limitados.

\subsubsection{Estructura de GANs (Generador y Discriminador)}  
La Figura \ref{2:fig47} muestra la relación entre el generador y el discriminador en una GAN. El discriminador debe determinar la procedencia de cada imagen que recibe, que puede provenir de un generador o de un conjunto de datos. Mientras tanto, los valores aleatorios se convierten en imágenes que el discriminador reconoce como pertenecientes al conjunto de datos a través del generador. \parencite{tec_goodfellow2014gan}

\begin{figure}[!ht]
	\begin{center}
		\includegraphics[width=0.75\textwidth]{2/figures/redgan.jpg}
		\caption[Red Generativa Antagónica de Imágenes]{Red Generativa Antagónica de Imágenes.\\
		Fuente: \cite{tec_goodfellow2014gan}. \citetitle{tec_goodfellow2014gan}.}
		\label{2:fig47}
	\end{center}
\end{figure}

El uso de GANs es amplia y no se limita a un tipo de datos específico. La Figura \ref{2:fig48} muestra una GAN con un generador y un discriminador de dos capas. En el generador, cada capa es gradualmente más grande, mientras que en el discriminador, cada capa se vuelve más pequeña hasta que se encuentra una neurona en la última capa. \parencite{tec_goodfellow2014gan}

\begin{figure}[!ht]
	\begin{center}
		\includegraphics[width=0.75\textwidth]{2/figures/redgan2.jpg}
		\caption[Red Generativa Antagónica de Imágenes]{Red Generativa Antagónica de Imágenes.\\
		Fuente: \cite{tec_goodfellow2014gan}. \citetitle{tec_goodfellow2014gan}.}
		\label{2:fig48}
	\end{center}
\end{figure}

Como se muestra en la Figura \ref{2:fig49} con imágenes en blanco y negro, la entrada del generador es una distribución aleatoria gaussiana. Su salida es comparable a la del conjunto de datos, y la capa de salida debe tener suficientes neuronas dispuestas de manera adecuada para producir datos con la misma estructura que el conjunto de datos original, ya sea imágenes, audio o cualquier otro tipo de datos. Por ejemplo, si se quieren imágenes de 20 x 20 píxeles, el generador debe producir 400 neuronas. Cada capa del generador es más grande que la anterior y generalmente utiliza la activación Selu, excepto la capa final, que utiliza Sigmoide. \parencite{tec_goodfellow2014gan}

\begin{figure}[!ht]
	\begin{center}
		\includegraphics[width=0.75\textwidth]{2/figures/redgan3.jpg}
		\caption[Imágenes de Ruido Gaussiano]{Imágenes de Ruido Gaussiano.\\
		Fuente: \cite{tec_goodfellow2014gan}. \citetitle{tec_goodfellow2014gan}.}
		\label{2:fig49}
	\end{center}
\end{figure}
A lo largo del proceso de entrenamiento, el generador intenta engañar al discriminador para que clasifique sus imágenes como reales, mientras que el discriminador mejora en la detección de imágenes falsas. Este proceso de competencia mejora gradualmente la calidad de las imágenes generadas.  
\begin{itemize}
    \item \textbf{Aplicación en Segmentación:} Las GANs se utilizan en la segmentación de imágenes cuando se dispone de un conjunto de datos limitado, ya que el generador puede crear imágenes realistas que amplían el conjunto de entrenamiento y ayudan a mejorar la capacidad del modelo de segmentación \parencite{autor2020gans}.
\end{itemize}

\subsubsection{Aplicaciones de GANs en Segmentación}  
Las GANs se han utilizado con éxito en diversas aplicaciones de segmentación, especialmente cuando se enfrenta a desafíos como conjuntos de datos pequeños o imágenes ruidosas. Algunas de sus aplicaciones incluyen:
\begin{itemize}
    \item \textbf{Generación de datos sintéticos:} En áreas como la dermatología, donde puede ser difícil obtener grandes volúmenes de imágenes etiquetadas, las GANs pueden generar imágenes sintéticas que representan diversas condiciones de la piel, lo que amplía el conjunto de datos de entrenamiento.
    \item \textbf{Segmentación de imágenes:} Las GANs también se aplican directamente a la segmentación de imágenes, especialmente en la mejora de la precisión en bordes complejos, como los que definen arrugas o manchas, a través de la generación de nuevas muestras \parencite{autor2021gans_segmentacion}.
\end{itemize}

\subsubsection{Variantes de GANs (CycleGAN, Pix2Pix)}  
Existen variantes de las GANs que mejoran la capacidad de las redes para realizar tareas de segmentación de manera más efectiva:
\begin{itemize}
    \item \textbf{CycleGAN:} CycleGAN es una variante que se utiliza para la traducción de imágenes entre dominios, es decir, transformar imágenes de un estilo a otro, como convertir imágenes de baja resolución a alta resolución o generar imágenes en diferentes condiciones de iluminación. Este modelo puede ser útil en segmentación cuando las imágenes de entrada varían significativamente entre diferentes dominios \parencite{autor2019cyclegan}.
    \item \textbf{Pix2Pix:} Pix2Pix es otro modelo basado en GAN que se usa para la segmentación supervisada, donde el modelo aprende a mapear una imagen de entrada a una imagen de salida. Se ha aplicado exitosamente en tareas de segmentación de imágenes faciales y dermatológicas, donde se requiere una alta precisión en los bordes de las características segmentadas \parencite{autor2019pix2pix}.
\end{itemize}

\subsubsection{Desafíos de las GANs}  
A pesar de su éxito, las GANs enfrentan varios desafíos importantes:
\begin{itemize}
    \item \textbf{Inestabilidad en el entrenamiento:} Durante el entrenamiento, el generador y el discriminador pueden no converger correctamente, lo que puede llevar a resultados inconsistentes o de baja calidad.
    \item \textbf{Modo colapso:} Un desafío común en las GANs es el "modo colapso", donde el generador produce una variedad limitada de muestras, afectando la diversidad de los datos generados. Este problema puede resultar en segmentaciones menos precisas o en la falta de variabilidad en las características segmentadas \parencite{autor2022challenges_gans}.
\end{itemize}

\subsection{Modelos Avanzados de Segmentación en Imágenes Médicas}
%
\subsubsection{Introducción a las redes de atención (Attention Networks) y su rol en la precisión de la segmentación}
Las redes de atención, como las arquitecturas basadas en atención (Attention Mechanisms), han emergido como una de las tecnologías más poderosas para mejorar el rendimiento de modelos de aprendizaje profundo, especialmente en tareas de segmentación de imágenes. Estas redes permiten que el modelo se enfoque dinámicamente en las partes más relevantes de una imagen, ajustando su atención a regiones específicas que contienen características clave. Este mecanismo es particularmente útil en imágenes dermatológicas, donde las características morfológicas, como arrugas, poros y manchas, pueden ser pequeñas, sutiles y difíciles de distinguir de otras partes de la imagen.

La introducción de redes de atención mejora la precisión de la segmentación al permitir que el modelo asigne un mayor peso a las regiones relevantes y minimice la interferencia de las áreas no importantes. Este enfoque facilita la identificación precisa de características morfológicas, lo cual es crucial para el análisis dermatológico. En el contexto de la piel, donde las variaciones de textura y color pueden ser complejas, las redes de atención ayudan a mejorar la segmentación y clasificación de estas características. Como resultado, la precisión en el diagnóstico y la personalización del tratamiento se ve significativamente aumentada, lo que contribuye a una mayor efectividad de las soluciones cosméticas y médicas \parencite{wang2018}.

%
\subsubsection{Aplicación de Generative Adversarial Networks (GAN) para mejorar la calidad de segmentación}
Las Generative Adversarial Networks (GAN) son una clase de modelos de aprendizaje profundo que consisten en dos redes neuronales: un generador y un discriminador. El generador crea imágenes sintéticas, mientras que el discriminador evalúa si las imágenes generadas son reales o falsas. Este enfoque adversarial permite que el generador produzca imágenes cada vez más realistas, lo que puede ser extremadamente útil en aplicaciones de segmentación de imágenes dermatológicas.

En el contexto de la segmentación de características cutáneas, como arrugas, poros y manchas, las GAN se utilizan para generar grandes cantidades de datos de entrenamiento de alta calidad. Estas imágenes sintéticas pueden complementar los conjuntos de datos reales, mejorando la diversidad y la variabilidad en las características de la piel, lo que a su vez ayuda a entrenar modelos de segmentación más robustos. Además, las GAN pueden generar imágenes con diferentes condiciones de iluminación, ángulos o incluso distorsiones en la piel, lo que permite a los modelos de segmentación aprender a identificar características cutáneas en una variedad más amplia de escenarios.

Esta técnica es particularmente valiosa en el ámbito dermatológico, donde la obtención de grandes cantidades de imágenes de alta calidad puede ser costosa o difícil debido a la privacidad de los pacientes o la variabilidad en las condiciones de la piel. Las GAN permiten superar estas limitaciones, mejorando la precisión y la generalización de los modelos de segmentación, lo que facilita una mejor evaluación estética y la personalización de tratamientos. \parencite{goodfellow2014}
%
\subsubsection{Comparación entre modelos basados en CNN y modelos híbridos en el contexto dermatológico}
La segmentación de imágenes dermatológicas es crucial para una correcta evaluación clínica y cosmética de la piel, donde las redes neuronales convolucionales (CNN) han demostrado ser eficaces al aprender características relevantes de manera jerárquica y sin necesidad de intervención manual. Sin embargo, las CNN pueden enfrentar desafíos cuando se trata de la segmentación en condiciones de iluminación cambiantes, variabilidad en tipos de piel y características pequeñas como poros o arrugas finas.

Los modelos híbridos, que combinan las capacidades de las CNN con técnicas clásicas de segmentación, ofrecen una alternativa interesante. Estos modelos integran la capacidad de las CNN para aprender representaciones complejas con enfoques más tradicionales como el umbralizado o la segmentación basada en regiones, lo que permite un control más preciso de las áreas de interés, especialmente cuando se requiere segmentar características cutáneas muy específicas. La comparación entre modelos CNN y modelos híbridos ayuda a identificar cuál de estos enfoques es más eficaz dependiendo del tipo de imagen, la complejidad de la tarea de segmentación y los requisitos de precisión.

Por ejemplo, en el análisis de la piel facial, los modelos híbridos podrían combinar las redes convolucionales para la detección de características complejas con métodos tradicionales para afinar los bordes de las regiones segmentadas. Esto puede mejorar significativamente la precisión y robustez del modelo, lo cual es esencial para aplicaciones dermatológicas, donde un pequeño error de segmentación puede afectar el diagnóstico o el tratamiento de afecciones cutáneas. \parencite{hussain2021}

\subsubsection{Métricas de evaluación: Sorensen-Dice, especificidad, precisión, sensibilidad}
Las métricas de evaluación son fundamentales para determinar la calidad y efectividad de los modelos de segmentación, especialmente en el ámbito médico y dermatológico. Entre estas métricas, el índice de Sorensen-Dice es ampliamente utilizado debido a su capacidad para medir la similitud entre las áreas segmentadas y las áreas reales de interés, lo cual es crítico cuando se analiza la precisión de la segmentación de lesiones o características cutáneas. Esta métrica es especialmente útil en la detección de anomalías de la piel, como manchas, arrugas y poros, ya que permite una comparación directa entre la segmentación automática y la segmentación realizada por expertos.

Junto al índice de Sorensen-Dice, otras métricas comunes en la evaluación de modelos de segmentación incluyen la precisión, que mide la exactitud de las regiones segmentadas positivas, y la sensibilidad, que evalúa la capacidad del modelo para detectar correctamente las áreas de interés. La especificidad, por otro lado, mide la capacidad del modelo para identificar correctamente las áreas no relevantes, lo que ayuda a reducir los falsos positivos en la segmentación de imágenes dermatológicas. \parencite{sorensen1948}

\subsubsection{Importancia de la precisión en segmentación de arrugas, poros y manchas para aplicaciones clínicas y cosméticas}
La precisión en la segmentación de características cutáneas como arrugas, poros y manchas es de vital importancia para una evaluación correcta en aplicaciones clínicas y cosméticas. En la práctica clínica, la segmentación precisa permite a los dermatólogos realizar diagnósticos más exactos, detectar signos tempranos de enfermedades de la piel y personalizar los tratamientos para cada paciente. En el ámbito cosmético, la segmentación precisa es esencial para ofrecer recomendaciones personalizadas sobre tratamientos faciales, como la mejora de la textura de la piel o la reducción de manchas y arrugas.

Un modelo de segmentación que no sea preciso puede dar lugar a resultados erróneos, afectando la calidad de los tratamientos recomendados y, por lo tanto, la satisfacción del cliente o del paciente. Además, la segmentación precisa facilita la evaluación del progreso de un tratamiento a lo largo del tiempo, lo que permite a los profesionales de la salud y belleza ajustar sus enfoques terapéuticos de manera más efectiva. \parencite{chuchu2020}

\subsubsection{Variabilidad en tipos de piel y condiciones externas (luz, color)}
Uno de los mayores desafíos en la segmentación dermatológica es la variabilidad en los tipos de piel y las condiciones externas, como la iluminación y los cambios en el color de la piel. Las pieles de diferentes tonos pueden presentar características distintas, como la intensidad del contraste entre la piel y las lesiones, lo que puede dificultar la tarea de segmentación. Además, las condiciones de iluminación, como la luz natural o artificial, pueden alterar la apariencia de las características cutáneas, complicando la segmentación precisa en entornos reales.

Por lo tanto, se necesita el desarrollo de modelos de segmentación más robustos que puedan adaptarse a estas variabilidades. Esto implica entrenar modelos utilizando una amplia variedad de datos, que incluyan diferentes tipos de piel, condiciones de iluminación y otros factores ambientales que puedan influir en la calidad de la imagen y en la precisión de la segmentación. \parencite{zhao2021}

\subsubsection{Complejidad de identificar características pequeñas como poros en imágenes de alta resolución}
La segmentación de características pequeñas, como los poros en la piel, es una tarea particularmente desafiante debido a su tamaño reducido y la alta resolución necesaria para detectarlos de manera precisa. Las imágenes dermatológicas a menudo contienen detalles finos que requieren técnicas avanzadas para identificar correctamente estos pequeños elementos sin incluir ruido o artefactos en la segmentación.

La identificación precisa de los poros es crucial, especialmente en aplicaciones cosméticas donde la evaluación de la textura de la piel es esencial para ofrecer tratamientos personalizados. Para abordar este desafío, se deben emplear técnicas de segmentación de alta resolución y redes neuronales profundas capaces de capturar los detalles más pequeños, incluso cuando los poros están parcialmente ocultos o tienen un contraste bajo respecto al resto de la piel. \parencite{yang2020}
% \subsection{Métricas de Evaluación}  
% Las métricas de evaluación son fundamentales para medir la precisión y eficacia de los modelos de segmentación de imágenes, ya que permiten comparar la segmentación automática generada por el modelo con las segmentaciones de referencia (verdaderas). A continuación se describen las principales métricas utilizadas en este tipo de análisis.

% \subsubsection{Índice de Sorensen-Dice (Dice Coefficient)}  
% El índice de Sorensen-Dice, o simplemente Dice coefficient, es una métrica ampliamente utilizada para evaluar la similitud entre dos conjuntos de datos segmentados. Esta métrica es especialmente útil en problemas de segmentación de imágenes médicas, donde es necesario comparar la segmentación automática con la segmentación de referencia.  
% \begin{itemize}
%     \item \textbf{Fórmula:}  
%     \begin{equation}\label{eq:Índice de Sorensen-Dice}
% 		\text{Dice} = \frac{2|A \cap B|}{|A| + |B|}
% 	\end{equation}
%     donde \( A \) y \( B \) son los conjuntos de píxeles segmentados de la imagen predicha y la imagen real, respectivamente.
%     \item \textbf{Interpretación:} El valor de Dice oscila entre 0 y 1, donde 1 indica una coincidencia perfecta entre las dos segmentaciones, y 0 indica ninguna superposición.
%     \item \textbf{Aplicación:} Es útil para tareas donde se requiere alta precisión en la identificación de áreas segmentadas, como en el análisis de manchas y arrugas en la piel, donde una segmentación precisa es crucial \parencite{autor2020dice}.
% \end{itemize}

% \subsubsection{Coeficiente de Jaccard (Intersection over Union, IoU)}  
% El coeficiente de Jaccard, también conocido como \( \text{Intersection over Union} \) (IoU), es otra métrica popular para evaluar la superposición entre dos conjuntos de segmentación. A diferencia del índice de Dice, IoU mide la relación entre la intersección de los conjuntos de píxeles predichos y reales con respecto a su unión total.  
% \begin{itemize}
%     \item \textbf{Fórmula:}  
%     \begin{equation}\label{eq:Coeficiente de Jaccard}
%     \text{IoU} = \frac{|A \cap B|}{|A \cup B|}
% 	\end{equation}
%     donde \( A \) y \( B \) son los conjuntos de píxeles segmentados de la imagen predicha y la imagen real, respectivamente.
%     \item \textbf{Interpretación:} El valor de IoU también varía entre 0 y 1. Un valor más alto indica una mayor superposición entre los segmentos predichos y reales. IoU es especialmente útil cuando se requiere evaluar la precisión en áreas de segmentación con bordes definidos, como en el análisis de arrugas y poros \parencite{autor2021iou}.
%     \item \textbf{Aplicación:} Es más severo que el índice de Dice, por lo que es adecuado para evaluar tareas donde la precisión en los bordes y las áreas superpuestas es esencial.
% \end{itemize}

% \subsubsection{Precisión (Precision)}  
% La precisión es una métrica que refleja la efectividad del modelo en evitar falsos positivos. Se calcula como la relación entre los verdaderos positivos y el total de elementos que el modelo ha predicho como positivos. En el contexto de la segmentación de imágenes, la precisión mide la exactitud de las regiones predichas como relevantes por el modelo.  
% \begin{itemize}
%     \item \textbf{Fórmula:}  
%     \[
%     \text{Precisión} = \frac{TP}{TP + FP}
%     \]
%     donde \( TP \) son los verdaderos positivos (píxeles correctamente predichos como parte de la característica) y \( FP \) son los falsos positivos (píxeles incorrectamente predichos como parte de la característica).
%     \item \textbf{Interpretación:} Un valor más alto de precisión indica que el modelo es más efectivo en minimizar los falsos positivos, lo cual es crítico en aplicaciones dermatológicas, donde un modelo debe evitar identificar incorrectamente áreas no relevantes como características de la piel.
%     \item \textbf{Aplicación:} Es útil para tareas donde el modelo debe ser riguroso en evitar predecir áreas de la imagen que no pertenecen a la característica de interés, como en el caso de la segmentación de manchas o poros \parencite{autor2019precision}.
% \end{itemize}

% \subsubsection{Entropía Cruzada (Cross-Entropy)}  
% La entropía cruzada es una función de pérdida utilizada comúnmente en problemas de clasificación y segmentación. Mide la disonancia o la diferencia entre la distribución de probabilidad predicha por el modelo y la distribución de probabilidad real (etiquetas verdaderas). En el contexto de la segmentación, la entropía cruzada es utilizada para entrenar el modelo, ya que penaliza las predicciones incorrectas.  
% \begin{itemize}
%     \item \textbf{Fórmula:}  
%     \[
%     \text{Cross-Entropy} = -\sum_{i} y_i \log(p_i)
%     \]
%     donde \( y_i \) es la etiqueta real de la clase \( i \) y \( p_i \) es la probabilidad predicha para la clase \( i \).
%     \item \textbf{Interpretación:} Un valor bajo de entropía cruzada indica que el modelo ha aprendido bien a predecir las clases correctas, es decir, las características de la piel en las imágenes segmentadas. Un valor alto sugiere una mala predicción, lo que indica que el modelo está lejos de la distribución real.
%     \item \textbf{Aplicación:} La entropía cruzada es especialmente útil durante el proceso de entrenamiento para ajustar los parámetros del modelo y garantizar que la segmentación final sea lo más precisa posible, especialmente al tratar con características complejas de la piel como manchas o arrugas \parencite{autor2022crossentropy}.
% \end{itemize}